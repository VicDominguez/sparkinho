{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "import math\n",
    "import numpy as np\n",
    "import pyspark\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init()\n",
    "sc = pyspark.SparkContext(\"local[*]\", \"Proyecto distribuido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nIter = 20\n",
    "learningRate = 0.5\n",
    "lambda_reg = 0.1\n",
    "numberOfFeatures = 11\n",
    "path = \"botnet.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(x,y):\n",
    "    return np.sum([x,y],axis=0)\n",
    "def divideByRows(x):\n",
    "    return (x[0], x[1]/(numberOfRows.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile (filename):\n",
    "    \n",
    "    def row2Tuple(x):\n",
    "        \"\"\"\n",
    "        Takes one rdd row and creates a float tuple (x,y) \n",
    "        where x is the array of data of these row and y the label\n",
    "        \"\"\"\n",
    "        floatArray=[float(number) for number in x.split(\",\")]\n",
    "        return (np.array(floatArray[:-1]),floatArray[-1]) #tuple (array of x),y\n",
    "    \n",
    "    \"\"\"\n",
    "    This function normalizes RDD for each column to N(0,1)\n",
    "    :param filename: name of the spam dataset file 12 columns: 11 features/dimensions (X) + 1 column with labels (Y)\n",
    "        Y -- Train labels (0 if normal traffic, 1 if botnet) \n",
    "        m rows: number of examples (m) \n",
    "    :return: An RDD containing the data of filename. Each example (row) of the file corresponds to one RDD record. \n",
    "        Each record of the RDD is a tuple (X,y). “X” is an array containing the 11 features (float number) of an example\n",
    "        “y” is the 12th column of an example (integer 0/1) \n",
    "    \"\"\"\n",
    "    global sc #spark context\n",
    "    inputRdd = sc.textFile(filename).map(row2Tuple)\n",
    "    #rdd = inputRdd.collect()\n",
    "    #return sc.parallelize(inputRdd.take(100000))\n",
    "    return inputRdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize (RDD_Xy):\n",
    "    \"\"\"\n",
    "    This function normalizes RDD for each column to N(0,1)\n",
    "    :param RDD_Xy: is an RDD containing data examples. Each record of the RDD is a tuple (X,y). \n",
    "        “X” is an array containing the 11 features (float number) of an example \n",
    "        “y” is the label of the example (integer 0/1) \n",
    "    :return: An RDD rescaled to N(0,1) in each column (mean=0, standard deviation=1)\n",
    "    \"\"\"\n",
    "    def normalizeLine(line):\n",
    "        return np.array(\n",
    "            [(element - broadcastMean.value[index])/broadcastStdev.value[index] \n",
    "            for index,element in enumerate(line[0])]\n",
    "        ), line[1]\n",
    "    \n",
    "    rdd = RDD_Xy.map(lambda line: line[0]) #remove label\n",
    "    meanArray = rdd.sum()/numberOfRows.value\n",
    "    #print(meanArray)\n",
    "    broadcastMean = sc.broadcast(meanArray)\n",
    "    stdevArray=np.sqrt(rdd.map(lambda x: (x-broadcastMean.value)**2).sum()/numberOfRows.value)\n",
    "    #print(stdevArray)\n",
    "    \n",
    "    broadcastStdev = sc.broadcast(stdevArray)\n",
    "    \n",
    "    #rdd.map(lambda line: (line-broadcastMean.value)/broadcastStdev.value)\n",
    "    #return rdd.map(lambda line: (line-broadcastMean.value)/broadcastStdev.value)\n",
    "    return RDD_Xy.map(normalizeLine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(X,W,b):\n",
    "    y = np.dot(X,W) + b\n",
    "    return 1/(1+np.exp(-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doDb(dataset,w,b,m):\n",
    "    sumTerm = dataset.map(lambda x: sigmoid(x[0],w,b) - x[1])\n",
    "    sumatory = sumTerm.sum()\n",
    "    return sumatory/ m.value\n",
    "\n",
    "def doDw(dataset,w,b,m):\n",
    "    sumTerm = dataset.map(lambda row: row[0]*(sigmoid(row[0],w,b) - row[1]))\n",
    "    sumatory =  sumTerm.sum()\n",
    "    reg = lambda_reg*w\n",
    "    return (sumatory + reg) / m.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costFuncion(dataset,w,b,m,lambda_reg):\n",
    "    \n",
    "    firstTerm = dataset.map(lambda row:\n",
    "                           (row[1]*np.log(sigmoid(row[0],w,b))) + ((1-row[1])*np.log(1-sigmoid(row[0],w,b)))\n",
    "                           ).sum() / -m.value\n",
    "    secondTerm = (lambda_reg*np.sum(w**2)/(2*m.value))\n",
    "    return firstTerm + secondTerm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train (RDD_Xy, iterations, learning_rate, lambda_reg):\n",
    "    \"\"\"\n",
    "    This function computes accuracy of the model\n",
    "    :param RDD_Xy: RDD containing data examples. Each record of the RDD is a tuple (X,y). “X” is an array containing \n",
    "        the 11 features (float number) of an example “y” is the label of the example (integer 0/1) \n",
    "    :param iterations: number of iterations of the optimization loop\n",
    "    :param learning_rate: learning rate of the gradient descent\n",
    "    :param lambda_reg: regularization rate\n",
    "    :return: A list or array containing the weights “w” and bias “b” at the end of the training process\n",
    "    \"\"\"\n",
    "    \n",
    "    w = np.random.rand(11)\n",
    "    b = np.random.random_sample()\n",
    "    dw = np.empty(11)\n",
    "    db = 0\n",
    "    listOfErr = []\n",
    "    \n",
    "    for iteration in range(iterations):\n",
    "        start = time.perf_counter()\n",
    "        \n",
    "        dw = doDw(RDD_Xy,w,b,numberOfRows)\n",
    "        db = doDb(RDD_Xy,w,b,numberOfRows)\n",
    "        \n",
    "        w -= (learning_rate * dw)\n",
    "        b -= (learning_rate * db)\n",
    "                \n",
    "        end = time.perf_counter()\n",
    "                \n",
    "        err = costFuncion(RDD_Xy,w,b,numberOfRows,lambda_reg)\n",
    "        listOfErr.append(err)\n",
    "                \n",
    "        endErr = time.perf_counter()\n",
    "        print(\"Iteration {:2d} err: {}, time training: {:.3f} time accuracy: {:.3f}\".format(\n",
    "            iteration,err,end-start,endErr - end))\n",
    "    return np.append(w,b), np.array(listOfErr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy (w, b, RDD_Xy):\n",
    "\n",
    "    \"\"\"\n",
    "    This function computes accuracy of the model\n",
    "    :param w: weights\n",
    "    :param b: bias\n",
    "    :param RDD_Xy: RDD containing examples to be predicted\n",
    "    :return: The number of predictions that are correct divided by the number of records (examples) in RDD_xy\n",
    "    \"\"\"\n",
    "    \n",
    "    def compare(row):\n",
    "        yPred = predict(w,b,row[0])\n",
    "        if yPred==row[1]:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    return (RDD_Xy.map(compare).sum())/numberOfRows.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict (w, b, X):\n",
    "    \"\"\"\n",
    "    Predict function can be used for predicting a single example\n",
    "    :param w: weights\n",
    "    :param b: bias\n",
    "    :param X: Example to be predicted\n",
    "    :return: A value (0/1) corresponding to the prediction of X\n",
    "    \"\"\"\n",
    "    return np.round(sigmoid(X,w,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startRead = time.perf_counter()\n",
    "data = readFile(path)\n",
    "endRead = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfRows = sc.broadcast(data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read time: 3.233, normalize time: 68.698\n"
     ]
    }
   ],
   "source": [
    "startNormalize= time.perf_counter()\n",
    "data = normalize(data)\n",
    "endNormalize = time.perf_counter()\n",
    "\n",
    "print(\"Read time: {:.3f}, normalize time: {:.3f}\".format(endRead-startRead,endNormalize - startNormalize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([-0.79240977, -0.81309371, -0.42245076, -0.46646975, -0.52239296,\n",
       "         -0.35631957,  0.7370103 ,  0.52834963,  0.82717799,  0.47316616,\n",
       "          0.15895172]), 1.0)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws, listOffErr = train(data, nIter, learningRate, lambda_reg)\n",
    "w = ws[:-1]\n",
    "b = ws[-1]\n",
    "acc = accuracy(w,b,data)\n",
    "print(\"acc: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = [i for i in range(nIter)]\n",
    "\n",
    "plt.plot(listOffErr,marker=\"o\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.title(\"Error of accuraccy during training\")\n",
    "plt.xticks(x)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
